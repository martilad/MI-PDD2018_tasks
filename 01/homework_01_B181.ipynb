{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework nr. 1 - data visualization (deadline 25/10/2018)\n",
    "\n",
    "In short, the main task is to download data on theses defended at CTU from the Internet, store them in pandas Data Frame and then visualize some hidden information.\n",
    "  \n",
    "> The instructions are not given in details: It is up to you to come up with ideas on how to fulfill the particular tasks as best you can. Thinking of how to visualize the data is an important part of data visualization! ;)\n",
    "\n",
    "## What are you supposed to do:\n",
    "\n",
    "  1. Browse the web https://dspace.cvut.cz/?locale-attribute=en and find out how to download data on Bachelor and Master theses.\n",
    "  2. Download or scrape the data such that for each thesis you know the following:\n",
    "    * Faculty name, department name, thesis title, thesis type (bachelor/master), supervisor name, reviewer name, year (or date) of the defence, study programme and discipline, link to a webpage with details.\n",
    "  3. Store these data in one _csv_ file (should be handed in along with this notebook).\n",
    "  4. Use tools available for Python to plot charts and tables to visualize/display this information:\n",
    "    * Number of defended theses per year for CTU/Faculties. Distinguish the type of thesis.\n",
    "    * Find the departments/study programmes/supervisors/reviewers with highest numbers of thesis and come up with some nice plots and tables to depict their numbers.\n",
    "    * Mean/median/minimum/maximum number of supervised theses per year for faculties.\n",
    "    * Number (or fraction) of theses supervised by people with various degrees (Bc./Ing./Ph.D./ ...).\n",
    "\n",
    "**If you do all this properly, you will obtain 6 points**\n",
    "\n",
    "To earn **extra two points** you can do some of these:\n",
    "  * Use http://beakerx.com to make your notebook interactive in a meaningful way.\n",
    "  * Come up with some other reasonable and interesting views of data.\n",
    "  * Use your data to create an interactive webpage (HTML + JavaScript).\n",
    "\n",
    "## Comments\n",
    "\n",
    "  * Please follow the instructions from https://courses.fit.cvut.cz/MI-PDD/homeworks/index.html.\n",
    "  * If the reviewing teacher is not satisfied, he can give you another chance to rework your homework and to obtain more points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://dspace.cvut.cz/discover?order=desc&page=0&rpp=100&etal=0&group_by=none&sort_by=dc.date.issued_dt\n",
      "324\n",
      "<div class=\"simple-item-view-type word-break item-page-field-wrapper table\">\n",
      "<h5>Typ dokumentu</h5>DOKTORSKÁ PRÁCE<br/>DISSERTATION</div>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as skit\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# url with search form\n",
    "urlDist = '/discover' \n",
    "# main dpace url for find BP, DP\n",
    "urlMain = 'https://dspace.cvut.cz{}'\n",
    "\n",
    "data = {\n",
    "    'rpp' : '100',\n",
    "    'etal' : '0', \n",
    "    'group_by' : 'none', \n",
    "    'page' : '0',\n",
    "    'sort_by' : 'dc.date.issued_dt',\n",
    "    'order' : 'desc'}\n",
    "\n",
    "\n",
    "#pages = 40\n",
    "#data_all = pd.DataFrame()\n",
    "#page = requests.get(urlMain.format(urlSearch.format(0)))\n",
    "page = requests.get(urlMain.format(urlDist), data)\n",
    "print(page.url)\n",
    "#print(page.text)\n",
    "\n",
    "downloaded = 0\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "pages = soup.find(\"li\", {\"class\": \"last-page-link\"}).find(\"a\").get_text()\n",
    "print(pages)\n",
    "for i in soup.findAll(\"div\", {\"class\": \"row ds-artifact-item \"}):\n",
    "    one = requests.get(urlMain.format(i.find(\"a\").get(\"href\")))\n",
    "    if one.status_code != 200:\n",
    "        print(\"Cant reach the work page. Continue..\")\n",
    "        continue\n",
    "    oneWorkSoup = BeautifulSoup(one.text, \"html.parser\")\n",
    "    #print(one.url)\n",
    "    print(oneWorkSoup.find(\"div\", {\"class\" : \"simple-item-view-type word-break item-page-field-wrapper table\"}))\n",
    "    downloaded += 1\n",
    "    print(downloaded)\n",
    "    \n",
    "    #Faculty name\n",
    "    #department name \n",
    "    #thesis title\n",
    "    #thesis type (bachelor/master)\n",
    "    #supervisor name + title \n",
    "    #reviewer name + title\n",
    "    #year (or date) of the defence (maybe) \n",
    "    #study programme \n",
    "    #discipline\n",
    "    #link to a webpage with details\n",
    "    break\n",
    "    \n",
    "\n",
    "#one = requests.get(urlMain.format(soup.findAll(\"div\", {\"class\": \"row ds-artifact-item \"})[0].find(\"a\").get(\"href\")))\n",
    "#print(one.url)\n",
    "#print(soup.findAll(\"div\", {\"class\": \"row ds-artifact-item \"})[0].findAll(\"h4\", {\"class\": \"artifact-title\"})[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
